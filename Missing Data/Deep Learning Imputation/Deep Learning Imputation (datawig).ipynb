{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Deep Learning Imputation (datawig)</center>\n",
    "\n",
    "Datawig is a recent tool that utilises MXnetâ€™s Deep Neural Networks to predict missing values. It can run on a CPU as well as a GPU, and supports numerical values, categorical values and more generic data types such as unstructured text.\n",
    "\n",
    "The imputation model follows the approach of MICE, also referred as fully conditional specification: for each to-be-imputed column (referred to as output column), the user can specify the columns which might contain useful information for imputation (referred to as input columns).\n",
    "\n",
    "<u>Datawig showed favourable [results](https://jmlr.csail.mit.edu/papers/volume20/18-753/18-753.pdf) against:</u>\n",
    "- fancyimpute package: mean, KNN, matrix factorization\n",
    "- iterativeimputer: estimators included RandomForestregressor and linear regression which are similar to the missforest approach and the MICE with a linear model\n",
    "\n",
    "<u>Drawbacks:</u> \n",
    "- Difficult to set up and run \n",
    "- With custom imputation models, only one column can be imputed at one time \n",
    "- It can be slow\n",
    "\n",
    "**When to use datawig:** datawig is a very recent algorithm and it hasn't been tested as thoroughly as MICE. However, there are [suggestions](https://pubmed.ncbi.nlm.nih.gov/35455196/) about using it when there is less than 40% of missingness in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing datawig\n",
    "\n",
    "Datawig comes with MXnet which causes many dependency clashes with recent Python versions. To avoid this, you will need to [create a virtual environment](https://www.geeksforgeeks.org/set-up-virtual-environment-for-python-using-anaconda/) with an earlier version of Python such as 3.7. Then follow the steps below:\n",
    "\n",
    "1. Activate your new environment: `conda activate envname` <br>\n",
    "- Install datawig with pip: `pip install datawig` <br>\n",
    "- You may also need to downgrade numpy by installing an earlier version: `conda install -c conda-forge numpy=x.x.x`<br>\n",
    "- Switch to your new environment through the anaconda navigator, choose your favourite IDE and let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running datawig \n",
    "\n",
    "Datawig offers two methods for imputation\n",
    "- **SimpleImputer**: uses default encoders and featurizers that usually yield good results \n",
    "- **Imputer**: allows us to specify which encoder and featurizer to use for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to SimpleImputer (method 1)\n",
    "\n",
    "An easy way to use the SimpleImputer is with the complete() function. This takes a data frame as an argument and automatically imputes all missing values with all other columns as inputs.\n",
    "\n",
    "```\n",
    "# Basic parameters\n",
    "datawig.SimpleImputer.complete(df, precision_threshold = 0.8, inplace=True)\n",
    "```\n",
    "\n",
    "```\n",
    "# High accuracy parameters\n",
    "datawig.SimpleImputer.complete(\n",
    "    df, precision_threshold = 0.8,\n",
    "    inplace = True, hpo = True,   # Setting hpo to True can be slow!\n",
    "    iterations = 20     # Higher iterations, higher computational time\n",
    ")\n",
    "```\n",
    "\n",
    "The precision_threshold parameter is only valid for categorical variables (otherwise it is ignored). If the model cannot reach this threshold for a given value, that value will not be imputed; thus depending on the precision_threshold (default = 0.0), the returned data frame may still contain some missing values. The hpo parameter is used to optimize hyperparameters and takes a boolean value. The iterations parameter takes the number of iterations that we want to use for imputation. Research suggests that a value of 20 should be generally sufficient, but higher values can be used.\n",
    "\n",
    "A few things to consider before using this method:\n",
    "- It will not work properly if data types are not correctly specified (e.g. numeric columns passed as string) \n",
    "- It will return a  ValueError if columns with type category exist in the dataset\n",
    "- It will not impute categorical columns unless missingness is very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# datawig\n",
    "import datawig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Survived Pclass  \\\n",
       "PassengerId                   \n",
       "1                  0      3   \n",
       "2                  1      1   \n",
       "3                  1      3   \n",
       "4                  1      1   \n",
       "5                  0      3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833     C        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000     C        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pickle.load(open(\"titanic_df.p\",\"rb\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   Survived  891 non-null    category\n",
      " 1   Pclass    891 non-null    category\n",
      " 2   Name      891 non-null    object  \n",
      " 3   Sex       891 non-null    category\n",
      " 4   Age       714 non-null    float64 \n",
      " 5   SibSp     891 non-null    int64   \n",
      " 6   Parch     891 non-null    int64   \n",
      " 7   Ticket    891 non-null    object  \n",
      " 8   Fare      891 non-null    float64 \n",
      " 9   Cabin     204 non-null    object  \n",
      " 10  Embarked  889 non-null    category\n",
      "dtypes: category(4), float64(2), int64(2), object(3)\n",
      "memory usage: 59.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our missing data\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert category types to prevent ValueError\n",
    "df[[\"Survived\",\"Pclass\"]] = df[[\"Survived\",\"Pclass\"]].astype(\"int\")\n",
    "df[[\"Sex\",\"Embarked\"]] = df[[\"Sex\",\"Embarked\"]].astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age           0\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed = datawig.SimpleImputer.complete(df)\n",
    "df_imputed.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns were imputed except Cabin, a categorical column with high missingness. The authors of datawig argue that it will not impute when predictive accuracy is not high enough. This may explain the remaining NaNs, but let's try to overcome this by building a custom imputation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to SimpleImputer (method 2)\n",
    "\n",
    "The SimpleImputer also allows for **custom imputation models**. One thing to note with this approach is that the procedure must be repeated for every to-be-imputed column. \n",
    "\n",
    "```\n",
    "# Custom imputation model \n",
    "imputer = datawig.SimpleImputer(\n",
    "    input_columns=['input1', 'input2'], \n",
    "    output_column= 'output', \n",
    "    output_path = 'imputer_model'  # Stores model metrics\n",
    "    )\n",
    "```\n",
    "\n",
    "After building an imputation model, we will need some data to train it with and different data to test it on. If the dataset is not already split, datawig provides its own split function.\n",
    "\n",
    "```\n",
    "# Split data for SimpleImputer \n",
    "df_train, df_test = datawig.utils.random_split(df)\n",
    "```\n",
    "\n",
    "```\n",
    "# Fit model \n",
    "imputer_Cabin.fit(train_df = df_train, num_epochs = 50)\n",
    "```\n",
    "\n",
    "We can also fit with hyperparameter tuning: `imputer.fit_hpo(train_df=df_train)`. The num_epochs parameter defines how many times to loop through the network. A rule of thumb is to start with a value that is three times the number of columns in your data. \n",
    "\n",
    "```\n",
    "# Impute missing values and return original dataframe with predictions\n",
    "predictions = imputer.predict(df_test)\n",
    "\n",
    "# Calculate metrics \n",
    "metrics = imputer_Cabin.load_metrics()\n",
    "weighted_f1 = metrics['weighted_f1']\n",
    "avg_precision = metrics['avg_precision']\n",
    "print(\"weighted_f1 :\", weighted_f1, \"\\n\", \"avg_precision :\", avg_precision)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "df_train, df_test = datawig.utils.random_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom imputation model for Cabin \n",
    "imputer_Cabin = datawig.SimpleImputer(\n",
    "    input_columns=['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked'], \n",
    "    output_column= 'Cabin', \n",
    "    output_path = 'imputer_model'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datawig.simple_imputer.SimpleImputer at 0x7f2a3c5e8210>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model \n",
    "imputer_Cabin.fit(train_df = df_train, num_epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "predictions = imputer_Cabin.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_f1 : 0.6025641025641025 \n",
      " avg_precision : 0.6214285714285714\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics - datawig provides its own metrics for categorical variables\n",
    "metrics = imputer_Cabin.load_metrics()\n",
    "weighted_f1 = metrics['weighted_f1']\n",
    "avg_precision = metrics['avg_precision']\n",
    "print(\"weighted_f1 :\", weighted_f1, \"\\n\", \"avg_precision :\", avg_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction score is low but this is expected with such high missingness in the column. One way to improve the predictions is by providing the model with variables that are more 'additive'. This is where exploring missing data comes in handy as we get to **understand the relationships between variables**. Another way may be to improve the **balancing of classes** within the column. If a certain class dominates the column, the predictions will be biased towards that class. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final notes:**\n",
    "\n",
    "If you look at my notebook where I test the behaviour of datawig on a couple of datasets (titanic included), you will notice that here we got a higher accuracy score when imputing the Cabin column. This is because we carried out the imputations on Cabin after Age was imputed which means that the model had more data to learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputer\n",
    "\n",
    "The Imputer enables more flexibility with specifying model parameters, such as using particular encoders and featurizers.\n",
    "\n",
    "**ColumnEncoder:** Transforms the raw data of a column into an encoded numerical representation.\n",
    "- **<span style=\"color:purple\">SequentialEncoder</span>:** for sequences of string symbols (e.g. characters or words)\n",
    "- **<span style=\"color:purple\">BowEncoder</span>**: bag-of-word representation for strings, as sparse vectors\n",
    "- **<span style=\"color:purple\">CategoricalEncoder</span>**: for categorical variables (one-hot encoding)\n",
    "- **<span style=\"color:purple\">NumericalEncoder</span>**: for numerical values\n",
    "\n",
    "**Featurizer:** converts encoded data into features that will be used in the imputation model for training and prediction. There are a few options for Featurizers depending on which ColumnEncoder was used for a particular column.\n",
    "- **<span style=\"color:purple\">LSTMFeaturizer</span>** â€“ used with SequentialEncoder\n",
    "- **<span style=\"color:purple\">BowFeaturizer</span>** - used with BowEncoder \n",
    "- **<span style=\"color:purple\">EmbeddingFeaturizer</span>** - used with CategoricalEncoder\n",
    "- **<span style=\"color:purple\">NumericalFeaturizer</span>** - used with NumericalEncoder\n",
    "\n",
    "```\n",
    "# Specifying Encoders and Featurizers\n",
    "data_encoder_cols = [BowEncoder('input1'),\n",
    "                     BowEncoder('input2')]\n",
    "label_encoder_cols = [CategoricalEncoder('output')]\n",
    "data_featurizer_cols = [BowFeaturizer('input1'),\n",
    "                        BowFeaturizer('input2')] \n",
    "```\n",
    "\n",
    "For the input columns that contain data useful for imputation, the Imputer expects you to specify the particular encoders and featurizers. For the label column that your are trying to impute, only specifying the type of encoder is necessary.\n",
    "\n",
    "```\n",
    "imputer = Imputer(\n",
    "    data_featurizers=data_featurizer_cols,\n",
    "    label_encoders=label_encoder_cols,\n",
    "    data_encoders=data_encoder_cols,\n",
    "    output_path='imputer_model'\n",
    ")\n",
    "\n",
    "imputer.fit(train_df=df_train, num_epochs=50)\n",
    "predictions = imputer.predict(df_test)\n",
    "```\n",
    "We will carry out the imputation only on the categorical variable Cabin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "from datawig import Imputer\n",
    "from datawig.column_encoders import *\n",
    "from datawig.mxnet_input_symbols import *\n",
    "# from datawig.utils import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datawig.imputer.Imputer at 0x7f2a3c5cc710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying Encoders and Featurizers\n",
    "data_encoder_cols = [BowEncoder('Sex'),\n",
    "                     BowEncoder('Embarked')]\n",
    "label_encoder_cols = [CategoricalEncoder('Cabin')]\n",
    "data_featurizer_cols = [BowFeaturizer('Sex'),\n",
    "                        BowFeaturizer('Embarked')]\n",
    "\n",
    "imputer = Imputer(\n",
    "    data_featurizers=data_featurizer_cols,\n",
    "    label_encoders=label_encoder_cols,\n",
    "    data_encoders=data_encoder_cols,\n",
    "    output_path='imputer_model'\n",
    ")\n",
    "\n",
    "imputer.fit(train_df=df_train, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_imputed</th>\n",
       "      <th>Cabin_imputed_proba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wick, Mrs. George Dennick (Mary Hitchcock)</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36928</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>0.400003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Givard, Mr. Hans Kristensen</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250646</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>0.400720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Goncalves, Mr. Manuel Estanslas</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101306</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>0.400720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Backstrom, Mr. Karl Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3101278</td>\n",
       "      <td>15.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>0.400720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Hickman, Mr. Lewis</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>S.O.C. 14879</td>\n",
       "      <td>73.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>0.400720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass                                        Name  \\\n",
       "PassengerId                                                                 \n",
       "857                 1       1  Wick, Mrs. George Dennick (Mary Hitchcock)   \n",
       "214                 0       2                 Givard, Mr. Hans Kristensen   \n",
       "466                 0       3             Goncalves, Mr. Manuel Estanslas   \n",
       "207                 0       3                  Backstrom, Mr. Karl Alfred   \n",
       "666                 0       2                          Hickman, Mr. Lewis   \n",
       "\n",
       "                Sex   Age  SibSp  Parch              Ticket      Fare Cabin  \\\n",
       "PassengerId                                                                   \n",
       "857          female  45.0      1      1               36928  164.8667   NaN   \n",
       "214            male  30.0      0      0              250646   13.0000   NaN   \n",
       "466            male  38.0      0      0  SOTON/O.Q. 3101306    7.0500   NaN   \n",
       "207            male  32.0      1      0             3101278   15.8500   NaN   \n",
       "666            male  32.0      2      0        S.O.C. 14879   73.5000   NaN   \n",
       "\n",
       "            Embarked Cabin_imputed  Cabin_imputed_proba  \n",
       "PassengerId                                              \n",
       "857                S             C             0.400003  \n",
       "214                S             C             0.400720  \n",
       "466                S             C             0.400720  \n",
       "207                S             C             0.400720  \n",
       "666                S             C             0.400720  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed = imputer.predict(df_test)\n",
    "imputed.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
